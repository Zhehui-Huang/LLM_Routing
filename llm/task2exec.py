from utils import (ask_llm, read_txt_file, write_py_file, run_py_file, limit_text, extract_python_code,
                   check_log_file_empty, MAXIMUM_EXEC_TIME, MAXIMUM_TEXT_LENGTH, get_output_details)


def task2exec_res(args, client, file_base_name, task_name, city_num, messages, base_solution_path, base_log_path,
                  exec_detail_path, messages_path, instance_tid, outer_tid):
    tmp_reflect_num = 0
    tmp_log_file_path = None
    for i in range(args.reflect_num):
        print(f"Reflect count: {i}")
        with open(exec_detail_path, 'a') as file:
            file.write(f"\nReflect count: {i}\n===\n")

        # 1. LLM -> Code & extract code & write code
        code_solution_content, response_time = ask_llm(client=client, llm_model=args.llm_model, messages=messages)
        code_solution_content = extract_python_code(content=code_solution_content)

        sol_file_path = f'{base_solution_path}/{task_name}/{city_num}/{file_base_name}/{instance_tid}/{outer_tid}/solution_r{i}.py'
        write_py_file(path=sol_file_path, content=code_solution_content)

        # 2. Execute the code
        log_file_path = f'{base_log_path}/{task_name}/{city_num}/{file_base_name}/{instance_tid}/{outer_tid}/log_r{i}.txt'
        exec_status_str, execution_time, log_file_path = run_py_file(
            code_path=sol_file_path, log_path=log_file_path, max_exec_time=MAXIMUM_EXEC_TIME
        )

        # 3. Check execution results
        file_empty_str = 'EMPTY'
        if exec_status_str == 'success':
            # Check the content in log_file_path, if it is empty, then return 'fail', i, log_file_path
            file_empty_str = check_log_file_empty(file_path=log_file_path)
            if file_empty_str != 'EMPTY':
                with open(exec_detail_path, 'a') as file:
                    file.write(f"Ask LLM for code solution, response time: {response_time:.2f} seconds.\n")
                    file.write(f"Code solution execution status: {exec_status_str}, execution time: {execution_time}\n")
                with open(messages_path, 'a') as file:
                    file.write(f"Assistant - Solution: {sol_file_path}\n")

                return 'success', i, log_file_path

        # Setup some variables
        tmp_reflect_num = i
        tmp_log_file_path = log_file_path

        # 3.1 Assistant: code generated by LLM
        response_solution = {"role": "assistant", "content": code_solution_content}
        messages.append(response_solution)

        # 3.2 User: prompt to fix error
        # 3.2.1 Extract exec results
        log_content = read_txt_file(path=log_file_path)
        # Format the verifier log content
        log_content = get_output_details(content=log_content)
        clipped_log_content = limit_text(text=log_content, max_length=MAXIMUM_TEXT_LENGTH)

        # 3.2.2 Construct prompt
        if file_empty_str == 'EMPTY':
            fix_error_prompt = (
                f'Although the generated solution executed successfully, '
                f'the execution results does not output anything, such as tour information or travel cost.\n'
                f'Please check the code and try again.'
            )
            fix_error_message = f"User - execution does not output any results.\n"
        elif exec_status_str == 'timeout':
            fix_error_prompt = (
                f'Here is the execution information:\n'
                f'{clipped_log_content}\n'
                f'The generated code exceeds the time limit of {MAXIMUM_EXEC_TIME} seconds.\n\n'
                f'Please generate a more time-efficient method, using heuristics or approximation techniques if necessary.'
            )
            fix_error_message = f"User - execution timeout. Regenerate solutions.\n"
        elif exec_status_str == 'error':
            fix_error_prompt = (
                f'The generated code has bugs. Here is the execution information:\n'
                f'{clipped_log_content}\n'
                f'Please fix all bugs. If fixing the bugs is too complex, you may generate a new solution. '
                f'Feel free to use heuristics or approximation techniques if necessary.'
            )
            fix_error_message = f"User - ask LLM to regenerate code by fixing bugs.\n"
        else:
            raise ValueError(f"Unknown execution status: {exec_status_str}")

        # 3.3 User: append to messages
        user_prompt = {"role": "user", "content": fix_error_prompt}
        messages.append(user_prompt)

        with open(messages_path, 'a') as file:
            file.write(fix_error_message)

        # 4. Maintain exec_detail_path  & message path
        with open(exec_detail_path, 'a') as file:
            file.write(f"Ask LLM for code solution, response time: {response_time:.2f} seconds.\n")
            file.write(f"Code solution execution status: {exec_status_str}, execution time: {execution_time}\n")
        with open(messages_path, 'a') as file:
            file.write(f"Assistant - Solution: {sol_file_path}\n")

    return 'fail', tmp_reflect_num, tmp_log_file_path
